{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "from data import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Master.</th>\n",
       "      <th>Miss.</th>\n",
       "      <th>Mr.</th>\n",
       "      <th>Mrs.</th>\n",
       "      <th>Other</th>\n",
       "      <th>A_CABIN</th>\n",
       "      <th>B_CABIN</th>\n",
       "      <th>...</th>\n",
       "      <th>class_2</th>\n",
       "      <th>class_3</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "      <th>FamilyAboard</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>InCabin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived   Age     Fare  Master.  Miss.  Mr.  Mrs.  Other  A_CABIN  \\\n",
       "0         0  22.0   7.2500        0      0    1     0      0        0   \n",
       "1         1  38.0  71.2833        0      0    0     1      0        0   \n",
       "2         1  26.0   7.9250        0      1    0     0      0        0   \n",
       "3         1  35.0  53.1000        0      0    0     1      0        0   \n",
       "4         0  35.0   8.0500        0      0    1     0      0        0   \n",
       "\n",
       "   B_CABIN  ...  class_2  class_3  female  male  C  Q  S  FamilyAboard  \\\n",
       "0        0  ...        0        1       0     1  0  0  1             1   \n",
       "1        0  ...        0        0       1     0  1  0  0             1   \n",
       "2        0  ...        0        1       1     0  0  0  1             0   \n",
       "3        0  ...        0        0       1     0  0  0  1             1   \n",
       "4        0  ...        0        1       0     1  0  0  1             0   \n",
       "\n",
       "   IsAlone  InCabin  \n",
       "0    False    False  \n",
       "1    False     True  \n",
       "2     True    False  \n",
       "3    False     True  \n",
       "4     True    False  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = process.Data('train.csv').return_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.constant(np.array(df.drop(['Survived'], axis=1)), tf.float32)\n",
    "labels = tf.cast(df['Survived'], tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(['Survived'], axis=1), df['Survived'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.constant(np.array(X_train), tf.float32)\n",
    "X_test = tf.constant(np.array(X_test), tf.float32)\n",
    "y_train = tf.cast(y_train, tf.bool)\n",
    "y_test = tf.cast(y_test, tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 128)               3328      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 19,969\n",
      "Trainable params: 19,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(128, activation='sigmoid', input_shape=(data.shape[1],), \n",
    "                             kernel_initializer='normal', bias_initializer='zeros'))\n",
    "for i in range (0, 3):\n",
    "    model.add(keras.layers.Dense(units=64, kernel_initializer='normal',\n",
    "                     bias_initializer='zeros'))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dropout(.25))\n",
    "#model.add(keras.layers.Dense(12, activation='softmax'))\n",
    "model.add(keras.layers.Dense(units=1))\n",
    "model.add(Activation('linear'))\n",
    "#model.add(keras.layers.Dense(2, activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error',optimizer='rmsprop', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 569 samples, validate on 143 samples\n",
      "Epoch 1/100\n",
      "569/569 [==============================] - 1s 2ms/sample - loss: 0.4420 - accuracy: 0.5185 - val_loss: 0.2223 - val_accuracy: 0.6643\n",
      "Epoch 2/100\n",
      "569/569 [==============================] - 0s 125us/sample - loss: 0.3528 - accuracy: 0.5483 - val_loss: 0.2274 - val_accuracy: 0.6643\n",
      "Epoch 3/100\n",
      "569/569 [==============================] - 0s 137us/sample - loss: 0.3395 - accuracy: 0.5483 - val_loss: 0.2374 - val_accuracy: 0.6643\n",
      "Epoch 4/100\n",
      "569/569 [==============================] - 0s 139us/sample - loss: 0.3143 - accuracy: 0.5466 - val_loss: 0.2329 - val_accuracy: 0.7063\n",
      "Epoch 5/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.3115 - accuracy: 0.5360 - val_loss: 0.2143 - val_accuracy: 0.6643\n",
      "Epoch 6/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.3124 - accuracy: 0.5536 - val_loss: 0.2100 - val_accuracy: 0.6643\n",
      "Epoch 7/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.2941 - accuracy: 0.5466 - val_loss: 0.2058 - val_accuracy: 0.6643\n",
      "Epoch 8/100\n",
      "569/569 [==============================] - 0s 130us/sample - loss: 0.2605 - accuracy: 0.5817 - val_loss: 0.2022 - val_accuracy: 0.6643\n",
      "Epoch 9/100\n",
      "569/569 [==============================] - 0s 125us/sample - loss: 0.2639 - accuracy: 0.5782 - val_loss: 0.1991 - val_accuracy: 0.7343\n",
      "Epoch 10/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.2580 - accuracy: 0.5747 - val_loss: 0.2012 - val_accuracy: 0.7203\n",
      "Epoch 11/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.2538 - accuracy: 0.5870 - val_loss: 0.1854 - val_accuracy: 0.7343\n",
      "Epoch 12/100\n",
      "569/569 [==============================] - 0s 135us/sample - loss: 0.2418 - accuracy: 0.6204 - val_loss: 0.1979 - val_accuracy: 0.7273\n",
      "Epoch 13/100\n",
      "569/569 [==============================] - 0s 127us/sample - loss: 0.2338 - accuracy: 0.6344 - val_loss: 0.1766 - val_accuracy: 0.7133\n",
      "Epoch 14/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.2227 - accuracy: 0.6397 - val_loss: 0.1706 - val_accuracy: 0.7622\n",
      "Epoch 15/100\n",
      "569/569 [==============================] - 0s 127us/sample - loss: 0.2190 - accuracy: 0.6731 - val_loss: 0.1742 - val_accuracy: 0.7413\n",
      "Epoch 16/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.2162 - accuracy: 0.6784 - val_loss: 0.1645 - val_accuracy: 0.7692\n",
      "Epoch 17/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.2016 - accuracy: 0.7170 - val_loss: 0.1612 - val_accuracy: 0.7552\n",
      "Epoch 18/100\n",
      "569/569 [==============================] - 0s 139us/sample - loss: 0.1952 - accuracy: 0.6995 - val_loss: 0.1675 - val_accuracy: 0.7552\n",
      "Epoch 19/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.1974 - accuracy: 0.7346 - val_loss: 0.1463 - val_accuracy: 0.8042\n",
      "Epoch 20/100\n",
      "569/569 [==============================] - 0s 139us/sample - loss: 0.1834 - accuracy: 0.7540 - val_loss: 0.1417 - val_accuracy: 0.7972\n",
      "Epoch 21/100\n",
      "569/569 [==============================] - 0s 134us/sample - loss: 0.1736 - accuracy: 0.7540 - val_loss: 0.1400 - val_accuracy: 0.8042\n",
      "Epoch 22/100\n",
      "569/569 [==============================] - 0s 127us/sample - loss: 0.1783 - accuracy: 0.7610 - val_loss: 0.1572 - val_accuracy: 0.7762\n",
      "Epoch 23/100\n",
      "569/569 [==============================] - 0s 144us/sample - loss: 0.1720 - accuracy: 0.7663 - val_loss: 0.1372 - val_accuracy: 0.7902\n",
      "Epoch 24/100\n",
      "569/569 [==============================] - 0s 134us/sample - loss: 0.1681 - accuracy: 0.7698 - val_loss: 0.1363 - val_accuracy: 0.8182\n",
      "Epoch 25/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.1689 - accuracy: 0.7821 - val_loss: 0.1444 - val_accuracy: 0.8112\n",
      "Epoch 26/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.1688 - accuracy: 0.7715 - val_loss: 0.1384 - val_accuracy: 0.8182\n",
      "Epoch 27/100\n",
      "569/569 [==============================] - 0s 139us/sample - loss: 0.1623 - accuracy: 0.7961 - val_loss: 0.1357 - val_accuracy: 0.8112\n",
      "Epoch 28/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.1650 - accuracy: 0.7821 - val_loss: 0.1329 - val_accuracy: 0.8182\n",
      "Epoch 29/100\n",
      "569/569 [==============================] - 0s 134us/sample - loss: 0.1605 - accuracy: 0.7979 - val_loss: 0.1331 - val_accuracy: 0.7972\n",
      "Epoch 30/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.1537 - accuracy: 0.7926 - val_loss: 0.1308 - val_accuracy: 0.8182\n",
      "Epoch 31/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.1593 - accuracy: 0.7856 - val_loss: 0.1290 - val_accuracy: 0.8112\n",
      "Epoch 32/100\n",
      "569/569 [==============================] - 0s 144us/sample - loss: 0.1646 - accuracy: 0.7961 - val_loss: 0.1401 - val_accuracy: 0.8112\n",
      "Epoch 33/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.1531 - accuracy: 0.8014 - val_loss: 0.1411 - val_accuracy: 0.8182\n",
      "Epoch 34/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.1609 - accuracy: 0.8014 - val_loss: 0.1284 - val_accuracy: 0.8042\n",
      "Epoch 35/100\n",
      "569/569 [==============================] - 0s 125us/sample - loss: 0.1508 - accuracy: 0.7961 - val_loss: 0.1380 - val_accuracy: 0.7972\n",
      "Epoch 36/100\n",
      "569/569 [==============================] - 0s 126us/sample - loss: 0.1537 - accuracy: 0.8049 - val_loss: 0.1271 - val_accuracy: 0.8182\n",
      "Epoch 37/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.1489 - accuracy: 0.8120 - val_loss: 0.1263 - val_accuracy: 0.8252\n",
      "Epoch 38/100\n",
      "569/569 [==============================] - 0s 125us/sample - loss: 0.1487 - accuracy: 0.8102 - val_loss: 0.1366 - val_accuracy: 0.7972\n",
      "Epoch 39/100\n",
      "569/569 [==============================] - 0s 125us/sample - loss: 0.1496 - accuracy: 0.8172 - val_loss: 0.1320 - val_accuracy: 0.8042\n",
      "Epoch 40/100\n",
      "569/569 [==============================] - 0s 121us/sample - loss: 0.1510 - accuracy: 0.7979 - val_loss: 0.1316 - val_accuracy: 0.8112\n",
      "Epoch 41/100\n",
      "569/569 [==============================] - 0s 125us/sample - loss: 0.1436 - accuracy: 0.8190 - val_loss: 0.1345 - val_accuracy: 0.8042\n",
      "Epoch 42/100\n",
      "569/569 [==============================] - 0s 126us/sample - loss: 0.1467 - accuracy: 0.8067 - val_loss: 0.1460 - val_accuracy: 0.8252\n",
      "Epoch 43/100\n",
      "569/569 [==============================] - 0s 130us/sample - loss: 0.1495 - accuracy: 0.8137 - val_loss: 0.1288 - val_accuracy: 0.8182\n",
      "Epoch 44/100\n",
      "569/569 [==============================] - 0s 126us/sample - loss: 0.1513 - accuracy: 0.8049 - val_loss: 0.1242 - val_accuracy: 0.8252\n",
      "Epoch 45/100\n",
      "569/569 [==============================] - 0s 137us/sample - loss: 0.1468 - accuracy: 0.8278 - val_loss: 0.1288 - val_accuracy: 0.8252\n",
      "Epoch 46/100\n",
      "569/569 [==============================] - 0s 125us/sample - loss: 0.1425 - accuracy: 0.8172 - val_loss: 0.1337 - val_accuracy: 0.8112\n",
      "Epoch 47/100\n",
      "569/569 [==============================] - 0s 126us/sample - loss: 0.1463 - accuracy: 0.8207 - val_loss: 0.1288 - val_accuracy: 0.8252\n",
      "Epoch 48/100\n",
      "569/569 [==============================] - 0s 121us/sample - loss: 0.1470 - accuracy: 0.8260 - val_loss: 0.1256 - val_accuracy: 0.8252\n",
      "Epoch 49/100\n",
      "569/569 [==============================] - 0s 135us/sample - loss: 0.1430 - accuracy: 0.8207 - val_loss: 0.1301 - val_accuracy: 0.8042\n",
      "Epoch 50/100\n",
      "569/569 [==============================] - 0s 126us/sample - loss: 0.1464 - accuracy: 0.8137 - val_loss: 0.1295 - val_accuracy: 0.8042\n",
      "Epoch 51/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.1434 - accuracy: 0.8172 - val_loss: 0.1248 - val_accuracy: 0.8182\n",
      "Epoch 52/100\n",
      "569/569 [==============================] - 0s 125us/sample - loss: 0.1413 - accuracy: 0.8295 - val_loss: 0.1285 - val_accuracy: 0.8322\n",
      "Epoch 53/100\n",
      "569/569 [==============================] - 0s 126us/sample - loss: 0.1436 - accuracy: 0.8190 - val_loss: 0.1262 - val_accuracy: 0.8392\n",
      "Epoch 54/100\n",
      "569/569 [==============================] - 0s 130us/sample - loss: 0.1359 - accuracy: 0.8172 - val_loss: 0.1300 - val_accuracy: 0.8182\n",
      "Epoch 55/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.1403 - accuracy: 0.8243 - val_loss: 0.1309 - val_accuracy: 0.8182\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569/569 [==============================] - 0s 134us/sample - loss: 0.1387 - accuracy: 0.8260 - val_loss: 0.1250 - val_accuracy: 0.8252\n",
      "Epoch 57/100\n",
      "569/569 [==============================] - 0s 125us/sample - loss: 0.1374 - accuracy: 0.8243 - val_loss: 0.1296 - val_accuracy: 0.8182\n",
      "Epoch 58/100\n",
      "569/569 [==============================] - 0s 130us/sample - loss: 0.1363 - accuracy: 0.8383 - val_loss: 0.1278 - val_accuracy: 0.8182\n",
      "Epoch 59/100\n",
      "569/569 [==============================] - 0s 139us/sample - loss: 0.1397 - accuracy: 0.8225 - val_loss: 0.1274 - val_accuracy: 0.8042\n",
      "Epoch 60/100\n",
      "569/569 [==============================] - 0s 135us/sample - loss: 0.1439 - accuracy: 0.8067 - val_loss: 0.1306 - val_accuracy: 0.7972\n",
      "Epoch 61/100\n",
      "569/569 [==============================] - 0s 141us/sample - loss: 0.1399 - accuracy: 0.8172 - val_loss: 0.1401 - val_accuracy: 0.8042\n",
      "Epoch 62/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.1409 - accuracy: 0.8207 - val_loss: 0.1304 - val_accuracy: 0.8042\n",
      "Epoch 63/100\n",
      "569/569 [==============================] - 0s 123us/sample - loss: 0.1358 - accuracy: 0.8348 - val_loss: 0.1268 - val_accuracy: 0.8322\n",
      "Epoch 64/100\n",
      "569/569 [==============================] - 0s 135us/sample - loss: 0.1356 - accuracy: 0.8313 - val_loss: 0.1319 - val_accuracy: 0.8182\n",
      "Epoch 65/100\n",
      "569/569 [==============================] - 0s 121us/sample - loss: 0.1364 - accuracy: 0.8330 - val_loss: 0.1257 - val_accuracy: 0.8322\n",
      "Epoch 66/100\n",
      "569/569 [==============================] - 0s 127us/sample - loss: 0.1360 - accuracy: 0.8436 - val_loss: 0.1315 - val_accuracy: 0.8112\n",
      "Epoch 67/100\n",
      "569/569 [==============================] - 0s 121us/sample - loss: 0.1352 - accuracy: 0.8225 - val_loss: 0.1284 - val_accuracy: 0.8252\n",
      "Epoch 68/100\n",
      "569/569 [==============================] - 0s 130us/sample - loss: 0.1361 - accuracy: 0.8471 - val_loss: 0.1257 - val_accuracy: 0.8322\n",
      "Epoch 69/100\n",
      "569/569 [==============================] - 0s 137us/sample - loss: 0.1355 - accuracy: 0.8313 - val_loss: 0.1262 - val_accuracy: 0.8322\n",
      "Epoch 70/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.1403 - accuracy: 0.8243 - val_loss: 0.1248 - val_accuracy: 0.8322\n",
      "Epoch 71/100\n",
      "569/569 [==============================] - 0s 123us/sample - loss: 0.1340 - accuracy: 0.8260 - val_loss: 0.1329 - val_accuracy: 0.8182\n",
      "Epoch 72/100\n",
      "569/569 [==============================] - 0s 121us/sample - loss: 0.1336 - accuracy: 0.8278 - val_loss: 0.1276 - val_accuracy: 0.8322\n",
      "Epoch 73/100\n",
      "569/569 [==============================] - 0s 123us/sample - loss: 0.1334 - accuracy: 0.8348 - val_loss: 0.1355 - val_accuracy: 0.8182\n",
      "Epoch 74/100\n",
      "569/569 [==============================] - 0s 127us/sample - loss: 0.1315 - accuracy: 0.8278 - val_loss: 0.1387 - val_accuracy: 0.8182\n",
      "Epoch 75/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.1373 - accuracy: 0.8313 - val_loss: 0.1258 - val_accuracy: 0.8252\n",
      "Epoch 76/100\n",
      "569/569 [==============================] - 0s 127us/sample - loss: 0.1373 - accuracy: 0.8401 - val_loss: 0.1246 - val_accuracy: 0.8182\n",
      "Epoch 77/100\n",
      "569/569 [==============================] - 0s 138us/sample - loss: 0.1339 - accuracy: 0.8260 - val_loss: 0.1260 - val_accuracy: 0.8252\n",
      "Epoch 78/100\n",
      "569/569 [==============================] - 0s 135us/sample - loss: 0.1333 - accuracy: 0.8418 - val_loss: 0.1310 - val_accuracy: 0.8182\n",
      "Epoch 79/100\n",
      "569/569 [==============================] - 0s 134us/sample - loss: 0.1360 - accuracy: 0.8295 - val_loss: 0.1290 - val_accuracy: 0.8182\n",
      "Epoch 80/100\n",
      "569/569 [==============================] - 0s 135us/sample - loss: 0.1320 - accuracy: 0.8330 - val_loss: 0.1248 - val_accuracy: 0.8112\n",
      "Epoch 81/100\n",
      "569/569 [==============================] - 0s 139us/sample - loss: 0.1316 - accuracy: 0.8313 - val_loss: 0.1276 - val_accuracy: 0.8322\n",
      "Epoch 82/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.1360 - accuracy: 0.8366 - val_loss: 0.1259 - val_accuracy: 0.8322\n",
      "Epoch 83/100\n",
      "569/569 [==============================] - 0s 127us/sample - loss: 0.1340 - accuracy: 0.8330 - val_loss: 0.1389 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.1346 - accuracy: 0.8313 - val_loss: 0.1290 - val_accuracy: 0.8322\n",
      "Epoch 85/100\n",
      "569/569 [==============================] - 0s 139us/sample - loss: 0.1323 - accuracy: 0.8418 - val_loss: 0.1262 - val_accuracy: 0.8112\n",
      "Epoch 86/100\n",
      "569/569 [==============================] - 0s 139us/sample - loss: 0.1317 - accuracy: 0.8401 - val_loss: 0.1326 - val_accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "569/569 [==============================] - 0s 127us/sample - loss: 0.1299 - accuracy: 0.8383 - val_loss: 0.1297 - val_accuracy: 0.8112\n",
      "Epoch 88/100\n",
      "569/569 [==============================] - 0s 123us/sample - loss: 0.1302 - accuracy: 0.8313 - val_loss: 0.1280 - val_accuracy: 0.8322\n",
      "Epoch 89/100\n",
      "569/569 [==============================] - 0s 121us/sample - loss: 0.1299 - accuracy: 0.8401 - val_loss: 0.1318 - val_accuracy: 0.8252\n",
      "Epoch 90/100\n",
      "569/569 [==============================] - 0s 121us/sample - loss: 0.1332 - accuracy: 0.8401 - val_loss: 0.1341 - val_accuracy: 0.8182\n",
      "Epoch 91/100\n",
      "569/569 [==============================] - 0s 125us/sample - loss: 0.1312 - accuracy: 0.8348 - val_loss: 0.1262 - val_accuracy: 0.8182\n",
      "Epoch 92/100\n",
      "569/569 [==============================] - 0s 128us/sample - loss: 0.1336 - accuracy: 0.8295 - val_loss: 0.1315 - val_accuracy: 0.8182\n",
      "Epoch 93/100\n",
      "569/569 [==============================] - 0s 121us/sample - loss: 0.1336 - accuracy: 0.8295 - val_loss: 0.1284 - val_accuracy: 0.8182\n",
      "Epoch 94/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.1400 - accuracy: 0.8295 - val_loss: 0.1261 - val_accuracy: 0.8112\n",
      "Epoch 95/100\n",
      "569/569 [==============================] - 0s 130us/sample - loss: 0.1326 - accuracy: 0.8330 - val_loss: 0.1295 - val_accuracy: 0.8252\n",
      "Epoch 96/100\n",
      "569/569 [==============================] - 0s 135us/sample - loss: 0.1292 - accuracy: 0.8471 - val_loss: 0.1264 - val_accuracy: 0.8182\n",
      "Epoch 97/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.1294 - accuracy: 0.8348 - val_loss: 0.1256 - val_accuracy: 0.8252\n",
      "Epoch 98/100\n",
      "569/569 [==============================] - 0s 132us/sample - loss: 0.1309 - accuracy: 0.8436 - val_loss: 0.1305 - val_accuracy: 0.8322\n",
      "Epoch 99/100\n",
      "569/569 [==============================] - 0s 130us/sample - loss: 0.1374 - accuracy: 0.8313 - val_loss: 0.1257 - val_accuracy: 0.8112\n",
      "Epoch 100/100\n",
      "569/569 [==============================] - 0s 127us/sample - loss: 0.1300 - accuracy: 0.8436 - val_loss: 0.1263 - val_accuracy: 0.8252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x213bf54cf60>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "179/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 45us/sample - loss: 0.0801 - accuracy: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10293945805403773"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = process.Data('test.csv').return_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_classes(tf.constant(np.array(test), dtype=np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test = pd.concat([test.PassengerId, pd.DataFrame(preds),], axis=1)\n",
    "test = test.rename(columns={0:'Survived'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
